{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please look at \"FinalProject_RealTime\" file to understand the followiong code\n",
    "\n",
    "the code can take model and train it on multiple different computer while store the gradient graph as a count sketch and convert it back into gradient graph to make a full backward propogation algorithm and than disterbut the new step into the whole system.\n",
    "\n",
    "\n",
    "In this excersize we train LSTM model,\n",
    "\n",
    "Its pretty hard to train one so we just showing the concpet with count sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "localLossLs = []\n",
    "disLossLs=[]\n",
    "iterations = 30\n",
    "\n",
    "class VaultBasedOnCountSketch:\n",
    "\n",
    "    def __init__(self, w: int, d: int):\n",
    "\n",
    "        data = [[0 for _ in range(w)] for _ in range(d)]\n",
    "\n",
    "        self.data = data\n",
    "        self.w = w\n",
    "        self.d = d\n",
    "\n",
    "        self.index_str_to_hashs = {}\n",
    "        self.index_str_to_positive_negative = {}\n",
    "\n",
    "    def store_number(self, tensor_id: int, i_index: int, j_index: int, number_to_store: float, fixed_size: int = 8):\n",
    "\n",
    "        index_str = str(tensor_id) + \"_\" + str(i_index) + \"_\" + str(j_index)\n",
    "\n",
    "        if index_str not in self.index_str_to_hashs:\n",
    "            self.index_str_to_hashs[index_str] = [hash(index_str * (i + 1)) for i in range(self.d)]\n",
    "            self.index_str_to_positive_negative[index_str] = [1 if hash(\"min_\" + (index_str * (i + 1))) % 2 else -1 for\n",
    "                                                              i in range(self.d)]\n",
    "\n",
    "        hashes = self.index_str_to_hashs[index_str]\n",
    "        positivity = self.index_str_to_positive_negative[index_str]\n",
    "\n",
    "        number_to_store = int(number_to_store * (10 ** fixed_size))\n",
    "\n",
    "        for i in range(self.d):\n",
    "            _hash = hashes[i]\n",
    "            _positive = positivity[i]\n",
    "\n",
    "            index = _hash % self.w\n",
    "\n",
    "            self.data[i][index] += number_to_store * _positive\n",
    "\n",
    "    def get_count_of_line(self, tensor_id: int, i_index: int, j_index: int, fixed_size: int = 8):\n",
    "\n",
    "        arr = []\n",
    "        for row in range(self.d):\n",
    "\n",
    "            index_str = str(tensor_id) + \"_\" + str(i_index) + \"_\" + str(j_index)\n",
    "            hashes = self.index_str_to_hashs[index_str][row]\n",
    "            positivity = self.index_str_to_positive_negative[index_str][row]\n",
    "\n",
    "            col = hashes % self.w\n",
    "            arr.append((float(self.data[row][col] * positivity) / (10 ** fixed_size)))\n",
    "\n",
    "        arr.sort()\n",
    "\n",
    "        return arr[len(arr) // 2]\n",
    "\n",
    "    \n",
    "\n",
    "def get_vault(gradient, w, d):\n",
    "    \n",
    "    vault = VaultBasedOnCountSketch(w, d)\n",
    "\n",
    "    for index, tensor_params in enumerate(gradient):\n",
    "\n",
    "        params = tensor_params.tolist()\n",
    "        size = len(tensor_params.shape)\n",
    "\n",
    "        if size == 2:\n",
    "            for i in range(tensor_params.shape[0]):\n",
    "\n",
    "                for j in range(tensor_params.shape[1]):\n",
    "                    vault.store_number(index, i, j, params[i][j])\n",
    "        else:\n",
    "            for i in range(tensor_params.shape[0]):\n",
    "                vault.store_number(index, i, 0, params[i])\n",
    "\n",
    "\n",
    "    return vault\n",
    "\n",
    "\n",
    "def set_gradient(vault, gradient):\n",
    "    \n",
    "    for index, tensor_params in enumerate(gradient):\n",
    "\n",
    "        params = tensor_params.tolist()\n",
    "        size = len(tensor_params.shape)\n",
    "\n",
    "        if size == 2:\n",
    "            for i in range(tensor_params.shape[0]):\n",
    "\n",
    "                for j in range(tensor_params.shape[1]):\n",
    "                    tensor_params[i][j] = vault.get_count_of_line(index, i, j)\n",
    "        else:\n",
    "            for i in range(tensor_params.shape[0]):\n",
    "                tensor_params[i] = vault.get_count_of_line(index, i, 0, )\n",
    "\n",
    "                \n",
    "\n",
    "def length_of_weight(weights):\n",
    "\n",
    "    to_return = 1\n",
    "    for s in weights.shape:\n",
    "        to_return *= s\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def set_item(weights_list, index_of_weight, index_in_weight_list, weight, index_in_weight):\n",
    "\n",
    "    shape_size = len(weight.shape)\n",
    "\n",
    "    if shape_size == 4:\n",
    "\n",
    "        index_0 = index_in_weight % weight.shape[0]\n",
    "        index_in_weight //= weight.shape[0]\n",
    "\n",
    "        index_1 = index_in_weight % weight.shape[1]\n",
    "        index_in_weight //= weight.shape[1]\n",
    "\n",
    "        index_2 = index_in_weight % weight.shape[2]\n",
    "        index_in_weight //= weight.shape[2]\n",
    "\n",
    "        index_3 = index_in_weight % weight.shape[3]\n",
    "        index_in_weight //= weight.shape[3]\n",
    "\n",
    "        weight[index_0][index_1][index_2][index_3] = weights_list[index_0][index_1][index_2][index_3]\n",
    "\n",
    "    elif shape_size == 2:\n",
    "\n",
    "        index_0 = index_in_weight % weight.shape[0]\n",
    "        index_in_weight //= weight.shape[0]\n",
    "\n",
    "        index_1 = index_in_weight % weight.shape[1]\n",
    "        index_in_weight //= weight.shape[1]\n",
    "\n",
    "        weight[index_0][index_1] = weights_list[index_0][index_1]\n",
    "\n",
    "    elif shape_size == 1:\n",
    "\n",
    "        weight[index_in_weight] = weights_list[index_in_weight]\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"not supported !!!\")\n",
    "\n",
    "    return 0 \n",
    "\n",
    "\n",
    "def insert_weights(weights_list: list, model):\n",
    "\n",
    "    weight_list_index = 0\n",
    "    index_of_weight = 0\n",
    "\n",
    "    model_data = model.state_dict()\n",
    "\n",
    "    _index = 0\n",
    "    for key, weight in model_data.items():\n",
    "\n",
    "        weight = np.zeros(weight.shape)\n",
    "        weight_index = 0\n",
    "        length = length_of_weight(weight)\n",
    "\n",
    "        for index in range(length):\n",
    "\n",
    "           next_weight_needed = set_item(weights_list[_index],index_of_weight, weight_list_index,weight, weight_index)\n",
    "           weight_index += 1\n",
    "           weight_list_index += 1\n",
    "           if next_weight_needed:\n",
    "                index_of_weight += 1\n",
    "                weight_list_index = 0\n",
    "\n",
    "        model_data[key].cpu().detach()\n",
    "        model_data[key] = torch.tensor(weight).cuda()\n",
    "\n",
    "        _index += 1\n",
    "\n",
    "    model.load_state_dict(model_data)\n",
    "    \n",
    "def get_model_weight_data(model):\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    for item in model.parameters():\n",
    "        to_return.append(np.copy(item.cpu().detach().numpy()))\n",
    "\n",
    "\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def get_gradient(steped_model, real_model):\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    for i in range(len(real_model)):\n",
    "        \n",
    "        to_return.append(real_model[i] - steped_model[i])\n",
    "        \n",
    "    return to_return\n",
    "\n",
    "def create_new_weight_based_on_gradient(model, gradient):\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    for i in range(len(model)):\n",
    "        \n",
    "        to_return.append(model[i] + gradient[i])\n",
    "        \n",
    "    return to_return\n",
    "    \n",
    "def multi_party_training(models, X, Y, number_of_computers):\n",
    "    \n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        \n",
    "        vaults = []\n",
    "        gradients = []\n",
    "        total_loss = 0\n",
    "        count = 0\n",
    "        # get current model poarams state\n",
    "        # in every starting iteration all models should have the same weights params\n",
    "        current_model_data = get_model_weight_data(models[0])\n",
    "        \n",
    "        # all different servers learning on thier own on thier private data and creating a vault\n",
    "        for computer_index in range(number_of_computers):\n",
    "            \n",
    "            x = X\n",
    "            y = Y\n",
    "            model = models[computer_index].cpu()\n",
    "            \n",
    "            optim_base = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.98), eps=1e-9)\n",
    "            mse = nn.MSELoss()\n",
    "\n",
    "            # Learning step process\n",
    "            _y = model(x)\n",
    "            loss = mse(_y, y)\n",
    "            optim_base.zero_grad()\n",
    "            loss.backward()\n",
    "            optim_base.step()\n",
    "            total_loss += loss.cpu().detach().numpy()\n",
    "            count += 1\n",
    "            # get model state after one step\n",
    "            steped_model_data = get_model_weight_data(model)\n",
    "\n",
    "            # get gradient \n",
    "            gradient = get_gradient(current_model_data, steped_model_data)\n",
    "            \n",
    "            gradients.append(gradient)\n",
    "            \n",
    "            # create a vault\n",
    "            vault = get_vault(gradient, w, d)\n",
    "            \n",
    "            # send my vault to the master server\n",
    "            vaults.append(vault)\n",
    "            \n",
    "        # create new gradient based on all inputs\n",
    "        \n",
    "        for computer_index in range(number_of_computers):\n",
    "            set_gradient(vaults[computer_index], gradients[computer_index])\n",
    "        \n",
    "        new_weight = create_new_weight_based_on_gradient(gradients[0], gradients[1])\n",
    "        for computer_index in range(2, number_of_computers):\n",
    "            new_weight = create_new_weight_based_on_gradient(new_weight, gradients[computer_index])\n",
    "            \n",
    "        for index in range(len(new_weight)):\n",
    "            new_weight[index] /= number_of_computers\n",
    "        \n",
    "        # create new weight\n",
    "        new_weight = create_new_weight_based_on_gradient(current_model_data, new_weight)\n",
    "        \n",
    "        # insert new weight to model\n",
    "        for computer_index in range(number_of_computers):\n",
    "            insert_weights(new_weight, models[computer_index])\n",
    "\n",
    "        disLossLs.append(total_loss/count)\n",
    "        print(\"Train iter \" , iteration, \" - loss \", total_loss/count)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLossFromTensor(t):\n",
    "    strT = str(t)\n",
    "    return float(strT.split('(')[1].split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to learning the following sentence from the previus sentence - downloaded the 5 first chapters of my favorite book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "page = \"\"\n",
    "for i in range(1, 6):\n",
    "    with open(\"./page_\" + str(i) + \".txt\", \"r\",  encoding=\"utf8\") as file:\n",
    "        page += \" \" + file.read()\n",
    "\n",
    "\n",
    "words = page.split(\" \")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_index = {}\n",
    "\n",
    "for word in words:\n",
    "    \n",
    "    if word not in words_to_index:\n",
    "        words_to_index[word] = len(words_to_index)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(0, len(words) - 12, 6):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for j in range(6):\n",
    "        \n",
    "        x.append(words_to_index[words[i + j]])\n",
    "        y.append(words_to_index[words[i + j + 6]])\n",
    "        \n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, 1)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        return lstm_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmTagger = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(words_to_index) + 1, len(words_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter  0  - loss  tensor(962905.9375, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  1  - loss  tensor(962903., device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  2  - loss  tensor(962899.8750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  3  - loss  tensor(962896.9375, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  4  - loss  tensor(962894., device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  5  - loss  tensor(962891.0625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  6  - loss  tensor(962888.1250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  7  - loss  tensor(962885.1875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  8  - loss  tensor(962882.2500, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  9  - loss  tensor(962879.3125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  10  - loss  tensor(962876.6250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  11  - loss  tensor(962873.6875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  12  - loss  tensor(962870.9375, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  13  - loss  tensor(962868.1250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  14  - loss  tensor(962865.3750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  15  - loss  tensor(962862.5625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  16  - loss  tensor(962859.8125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  17  - loss  tensor(962857.1250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  18  - loss  tensor(962854.3750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  19  - loss  tensor(962851.6250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  20  - loss  tensor(962848.9375, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  21  - loss  tensor(962846.3125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  22  - loss  tensor(962843.6875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  23  - loss  tensor(962841.0625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  24  - loss  tensor(962838.4375, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  25  - loss  tensor(962835.8125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  26  - loss  tensor(962833.1875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  27  - loss  tensor(962830.6875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  28  - loss  tensor(962828.1875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Train iter  29  - loss  tensor(962825.5625, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstmTagger = lstmTagger.cuda()\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "X = X.cuda()\n",
    "Y = Y.type(torch.float).cuda()\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    \n",
    "    optim_base = torch.optim.Adam(lstmTagger.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "    mse = nn.MSELoss()\n",
    "    \n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    _Y = lstmTagger(X)\n",
    "    \n",
    "    loss = mse(_Y.view(-1, 1), Y.view(-1, 1))\n",
    "\n",
    "    optim_base.zero_grad()\n",
    "    loss.backward()\n",
    "    optim_base.step()\n",
    "\n",
    "    total_loss += loss.cpu().detach().numpy()\n",
    "    count += 1\n",
    "    \n",
    "    #loss /= count\n",
    "    localLossLs.append(getLossFromTensor(loss))   \n",
    "    print(\"Train iter \" , iteration, \" - loss \", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train by Sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_computers = 10\n",
    "\n",
    "models = [LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(words_to_index) + 1, len(words_to_index)) for i in range(number_of_computers)]\n",
    "\n",
    "model_structure = models[0].state_dict()\n",
    "\n",
    "models[0] = models[0].cuda()\n",
    "for i in range(1, number_of_computers):\n",
    "    models[i].load_state_dict(model_structure)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alon bar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1628, 6])) that is different to the input size (torch.Size([1628, 1, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter  0  - loss  962896.5625\n",
      "Train iter  1  - loss  962870.8125\n",
      "Train iter  2  - loss  962844.0625\n",
      "Train iter  3  - loss  962817.4375\n",
      "Train iter  4  - loss  962789.75\n",
      "Train iter  5  - loss  962759.5\n",
      "Train iter  6  - loss  962728.875\n",
      "Train iter  7  - loss  962697.3125\n",
      "Train iter  8  - loss  962666.4375\n",
      "Train iter  9  - loss  962633.625\n",
      "Train iter  10  - loss  962600.0\n",
      "Train iter  11  - loss  962564.5\n",
      "Train iter  12  - loss  962527.75\n",
      "Train iter  13  - loss  962490.3125\n",
      "Train iter  14  - loss  962450.25\n",
      "Train iter  15  - loss  962407.625\n",
      "Train iter  16  - loss  962363.75\n",
      "Train iter  17  - loss  962319.375\n",
      "Train iter  18  - loss  962273.5\n",
      "Train iter  19  - loss  962227.625\n",
      "Train iter  20  - loss  962183.625\n",
      "Train iter  21  - loss  962142.0625\n",
      "Train iter  22  - loss  962102.5\n",
      "Train iter  23  - loss  962065.3125\n",
      "Train iter  24  - loss  962029.1875\n",
      "Train iter  25  - loss  961993.6875\n",
      "Train iter  26  - loss  961960.8125\n",
      "Train iter  27  - loss  961929.1875\n",
      "Train iter  28  - loss  961898.5\n",
      "Train iter  29  - loss  961868.0625\n"
     ]
    }
   ],
   "source": [
    "w = 1000\n",
    "d = 25\n",
    "X = X.cpu()\n",
    "Y = Y.cpu()\n",
    "multi_party_training(models, X, Y, number_of_computers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "30\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "it = np.arange(1,iteration+2)\n",
    "print(it)\n",
    "print(len(localLossLs))\n",
    "plt.plot(it,localLossLs,label = \"Local Training\")\n",
    "plt.plot(it,disLossLs,label = \"Distributed Training\")\n",
    "plt.title(\"LSTM : MSE Loss Over Iterations\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
