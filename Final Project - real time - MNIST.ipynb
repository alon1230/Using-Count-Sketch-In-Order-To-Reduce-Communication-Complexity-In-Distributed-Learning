{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please look at \"FinalProject_RealTime\" file to understand the followiong code\n",
    "\n",
    "the code can take model and train it on multiple different computer while store the gradient graph as a count sketch and convert it back into gradient graph to make a full backward propogation algorithm and than disterbut the new step into the whole system.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "iterations = 30\n",
    "disLossLs = []\n",
    "localLossLs = []\n",
    "\n",
    "class VaultBasedOnCountSketch:\n",
    "\n",
    "    def __init__(self, w: int, d: int):\n",
    "\n",
    "        data = [[0 for _ in range(w)] for _ in range(d)]\n",
    "\n",
    "        self.data = data\n",
    "        self.w = w\n",
    "        self.d = d\n",
    "\n",
    "        self.index_str_to_hashs = {}\n",
    "        self.index_str_to_positive_negative = {}\n",
    "\n",
    "    def store_number(self, tensor_id: int, i_index: int, j_index: int, number_to_store: float, fixed_size: int = 8):\n",
    "\n",
    "        index_str = str(tensor_id) + \"_\" + str(i_index) + \"_\" + str(j_index)\n",
    "\n",
    "        if index_str not in self.index_str_to_hashs:\n",
    "            self.index_str_to_hashs[index_str] = [hash(index_str * (i + 1)) for i in range(self.d)]\n",
    "            self.index_str_to_positive_negative[index_str] = [1 if hash(\"min_\" + (index_str * (i + 1))) % 2 else -1 for\n",
    "                                                              i in range(self.d)]\n",
    "\n",
    "        hashes = self.index_str_to_hashs[index_str]\n",
    "        positivity = self.index_str_to_positive_negative[index_str]\n",
    "\n",
    "        number_to_store = int(number_to_store * (10 ** fixed_size))\n",
    "\n",
    "        for i in range(self.d):\n",
    "            _hash = hashes[i]\n",
    "            _positive = positivity[i]\n",
    "\n",
    "            index = _hash % self.w\n",
    "\n",
    "            self.data[i][index] += number_to_store * _positive\n",
    "\n",
    "    def get_count_of_line(self, tensor_id: int, i_index: int, j_index: int, fixed_size: int = 8):\n",
    "\n",
    "        arr = []\n",
    "        for row in range(self.d):\n",
    "\n",
    "            index_str = str(tensor_id) + \"_\" + str(i_index) + \"_\" + str(j_index)\n",
    "            hashes = self.index_str_to_hashs[index_str][row]\n",
    "            positivity = self.index_str_to_positive_negative[index_str][row]\n",
    "\n",
    "            col = hashes % self.w\n",
    "            arr.append((float(self.data[row][col] * positivity) / (10 ** fixed_size)))\n",
    "\n",
    "        arr.sort()\n",
    "\n",
    "        return arr[len(arr) // 2]\n",
    "\n",
    "    \n",
    "\n",
    "def get_vault(gradient, w, d):\n",
    "    \n",
    "    vault = VaultBasedOnCountSketch(w, d)\n",
    "\n",
    "    for index, tensor_params in enumerate(gradient):\n",
    "\n",
    "        params = tensor_params.tolist()\n",
    "        size = len(tensor_params.shape)\n",
    "\n",
    "        if size == 2:\n",
    "            for i in range(tensor_params.shape[0]):\n",
    "\n",
    "                for j in range(tensor_params.shape[1]):\n",
    "                    vault.store_number(index, i, j, params[i][j])\n",
    "        else:\n",
    "            for i in range(tensor_params.shape[0]):\n",
    "                vault.store_number(index, i, 0, params[i])\n",
    "\n",
    "\n",
    "    return vault\n",
    "\n",
    "\n",
    "def set_gradient(vault, gradient):\n",
    "    \n",
    "    for index, tensor_params in enumerate(gradient):\n",
    "\n",
    "        params = tensor_params.tolist()\n",
    "        size = len(tensor_params.shape)\n",
    "\n",
    "        if size == 2:\n",
    "            for i in range(tensor_params.shape[0]):\n",
    "\n",
    "                for j in range(tensor_params.shape[1]):\n",
    "                    tensor_params[i][j] = vault.get_count_of_line(index, i, j)\n",
    "        else:\n",
    "            for i in range(tensor_params.shape[0]):\n",
    "                tensor_params[i] = vault.get_count_of_line(index, i, 0, )\n",
    "\n",
    "                \n",
    "\n",
    "def length_of_weight(weights):\n",
    "\n",
    "    to_return = 1\n",
    "    for s in weights.shape:\n",
    "        to_return *= s\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def set_item(weights_list, index_of_weight, index_in_weight_list, weight, index_in_weight):\n",
    "\n",
    "    shape_size = len(weight.shape)\n",
    "\n",
    "    if shape_size == 4:\n",
    "\n",
    "        index_0 = index_in_weight % weight.shape[0]\n",
    "        index_in_weight //= weight.shape[0]\n",
    "\n",
    "        index_1 = index_in_weight % weight.shape[1]\n",
    "        index_in_weight //= weight.shape[1]\n",
    "\n",
    "        index_2 = index_in_weight % weight.shape[2]\n",
    "        index_in_weight //= weight.shape[2]\n",
    "\n",
    "        index_3 = index_in_weight % weight.shape[3]\n",
    "        index_in_weight //= weight.shape[3]\n",
    "\n",
    "        weight[index_0][index_1][index_2][index_3] = weights_list[index_0][index_1][index_2][index_3]\n",
    "\n",
    "    elif shape_size == 2:\n",
    "\n",
    "        index_0 = index_in_weight % weight.shape[0]\n",
    "        index_in_weight //= weight.shape[0]\n",
    "\n",
    "        index_1 = index_in_weight % weight.shape[1]\n",
    "        index_in_weight //= weight.shape[1]\n",
    "\n",
    "        weight[index_0][index_1] = weights_list[index_0][index_1]\n",
    "\n",
    "    elif shape_size == 1:\n",
    "\n",
    "        weight[index_in_weight] = weights_list[index_in_weight]\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"not supported !!!\")\n",
    "\n",
    "    return 0 \n",
    "\n",
    "\n",
    "def insert_weights(weights_list: list, model):\n",
    "\n",
    "    weight_list_index = 0\n",
    "    index_of_weight = 0\n",
    "\n",
    "    model_data = model.state_dict()\n",
    "\n",
    "    _index = 0\n",
    "    for key, weight in model_data.items():\n",
    "\n",
    "        weight = np.zeros(weight.shape)\n",
    "        weight_index = 0\n",
    "        length = length_of_weight(weight)\n",
    "\n",
    "        for index in range(length):\n",
    "\n",
    "           next_weight_needed = set_item(weights_list[_index],index_of_weight, weight_list_index,weight, weight_index)\n",
    "           weight_index += 1\n",
    "           weight_list_index += 1\n",
    "           if next_weight_needed:\n",
    "                index_of_weight += 1\n",
    "                weight_list_index = 0\n",
    "\n",
    "        model_data[key].cpu().detach()\n",
    "        model_data[key] = torch.tensor(weight).cuda()\n",
    "\n",
    "        _index += 1\n",
    "\n",
    "    model.load_state_dict(model_data)\n",
    "    \n",
    "def get_model_weight_data(model):\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    for item in model.parameters():\n",
    "        to_return.append(np.copy(item.detach().numpy()))\n",
    "\n",
    "\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def get_gradient(steped_model, real_model):\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    for i in range(len(real_model)):\n",
    "        \n",
    "        to_return.append(real_model[i] - steped_model[i])\n",
    "        \n",
    "    return to_return\n",
    "\n",
    "def create_new_weight_based_on_gradient(model, gradient):\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    for i in range(len(model)):\n",
    "        \n",
    "        to_return.append(model[i] + gradient[i])\n",
    "        \n",
    "    return to_return\n",
    "    \n",
    "def multi_party_training(models, X, Y, number_of_computers):\n",
    "    \n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        \n",
    "        vaults = []\n",
    "        gradients = []\n",
    "        \n",
    "        total_loss = 0\n",
    "        count = 0\n",
    "        \n",
    "        # get current model poarams state\n",
    "        # in every starting iteration all models should have the same weights params\n",
    "        current_model_data = get_model_weight_data(models[0])\n",
    "        \n",
    "        # all different servers learning on thier own on thier private data and creating a vault\n",
    "        for computer_index in range(number_of_computers):\n",
    "            \n",
    "            x = X[computer_index]\n",
    "            y = Y[computer_index]\n",
    "            model = models[computer_index]\n",
    "            \n",
    "            optim_base = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.98), eps=1e-9)\n",
    "            mse = nn.MSELoss()\n",
    "\n",
    "            # Learning step process\n",
    "            _y = model(x)\n",
    "            loss = mse(_y, y)\n",
    "            optim_base.zero_grad()\n",
    "            loss.backward()\n",
    "            optim_base.step()\n",
    "            total_loss += loss.cpu().detach().numpy()\n",
    "            count += 1\n",
    "            # get model state after one step\n",
    "            steped_model_data = get_model_weight_data(model)\n",
    "\n",
    "            # get gradient \n",
    "            gradient = get_gradient(current_model_data, steped_model_data)\n",
    "            \n",
    "            gradients.append(gradient)\n",
    "            \n",
    "            # create a vault\n",
    "            vault = get_vault(gradient, w, d)\n",
    "            \n",
    "            # send my vault to the master server\n",
    "            vaults.append(vault)\n",
    "            \n",
    "        # create new gradient based on all inputs\n",
    "        \n",
    "        for computer_index in range(number_of_computers):\n",
    "            set_gradient(vaults[computer_index], gradients[computer_index])\n",
    "        \n",
    "        new_weight = create_new_weight_based_on_gradient(gradients[0], gradients[1])\n",
    "        for computer_index in range(2, number_of_computers):\n",
    "            new_weight = create_new_weight_based_on_gradient(new_weight, gradients[computer_index])\n",
    "            \n",
    "        for index in range(len(new_weight)):\n",
    "            new_weight[index] /= number_of_computers\n",
    "        \n",
    "        # create new weight\n",
    "        new_weight = create_new_weight_based_on_gradient(current_model_data, new_weight)\n",
    "        \n",
    "        # insert new weight to model\n",
    "        for computer_index in range(number_of_computers):\n",
    "            insert_weights(new_weight, models[computer_index])\n",
    "        disLossLs.append(total_loss/count)\n",
    "        print(\"Train iter \" , iteration, \" - loss \", total_loss/count)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLossFromTensor(t):\n",
    "    strT = str(t)\n",
    "    return float(strT.split('(')[1].split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alon bar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MNISTClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        \n",
    "        self.dense1 = nn.Linear(28 * 28, 256)\n",
    "        self.dense2 = nn.Linear(256, 64)\n",
    "        self.dense3 = nn.Linear(64, 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(-1, 784)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = torch.tanh(self.dense2(x))\n",
    "        x = self.dense3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter  0  - loss  2.010212083964714\n",
      "Train iter  1  - loss  1.058229140222454\n",
      "Train iter  2  - loss  0.964088356126346\n",
      "Train iter  3  - loss  0.9261145854968507\n",
      "Train iter  4  - loss  0.8907798023016722\n",
      "Train iter  5  - loss  0.8828218596131563\n",
      "Train iter  6  - loss  0.870905324530754\n",
      "Train iter  7  - loss  0.8628535413824673\n",
      "Train iter  8  - loss  0.8498673857624597\n",
      "Train iter  9  - loss  0.8459799029965644\n",
      "Train iter  10  - loss  0.839792923282967\n",
      "Train iter  11  - loss  0.8364329135684825\n",
      "Train iter  12  - loss  0.842032474558999\n",
      "Train iter  13  - loss  0.8387383366190294\n",
      "Train iter  14  - loss  0.8305558402146866\n",
      "Train iter  15  - loss  0.8309564457805172\n",
      "Train iter  16  - loss  0.8401666730801179\n",
      "Train iter  17  - loss  0.8223733581713776\n",
      "Train iter  18  - loss  0.8258575378482276\n",
      "Train iter  19  - loss  0.8113905402865491\n",
      "Train iter  20  - loss  0.8131064558937859\n",
      "Train iter  21  - loss  0.8210785819777547\n",
      "Train iter  22  - loss  0.8148299100270657\n",
      "Train iter  23  - loss  0.8142159615498362\n",
      "Train iter  24  - loss  0.814902466084403\n",
      "Train iter  25  - loss  0.8028280867188216\n",
      "Train iter  26  - loss  0.7985298751450297\n",
      "Train iter  27  - loss  0.8149972563740541\n",
      "Train iter  28  - loss  0.8100222009998649\n",
      "Train iter  29  - loss  0.8096089407579222\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MNISTClassifier().cuda()\n",
    "\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    \n",
    "    optim_base = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "    mse = nn.MSELoss()\n",
    "    \n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    for X, Y in train_loader:\n",
    "        \n",
    "        X = X.cuda()\n",
    "        Y = Y.cuda()\n",
    "        \n",
    "        Y = Y.type(torch.float)\n",
    "        \n",
    "        _Y = model(X)\n",
    "        loss = mse(_Y.view(-1, 1), Y.view(-1, 1))\n",
    "        \n",
    "        optim_base.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_base.step()\n",
    "        \n",
    "        total_loss += loss.cpu().detach().numpy()\n",
    "        count += 1\n",
    "    \n",
    "    total_loss /= count\n",
    "    localLossLs.append(total_loss)\n",
    "    \n",
    "        \n",
    "    print(\"Train iter \" , iteration, \" - loss \", total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss  0.9115328788757324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_loss = 0\n",
    "count = 0\n",
    "for X, Y in test_loader:\n",
    "    \n",
    "    X = X.cuda()\n",
    "    Y = Y.cuda()\n",
    "    \n",
    "    # Learning step process\n",
    "    _Y = model(X)\n",
    "    \n",
    "    Y = Y.type(torch.float)\n",
    "    \n",
    "    loss = mse(_Y.view(-1, 1), Y.view(-1, 1))\n",
    "    total_loss += loss.cpu().detach().numpy()\n",
    "    count += 1\n",
    "    \n",
    "print(\"Test Loss \", total_loss / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train by Sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_computers = 10\n",
    "\n",
    "models = [MNISTClassifier() for i in range(number_of_computers)]\n",
    "\n",
    "model_structure = models[0].state_dict()\n",
    "\n",
    "for i in range(1, number_of_computers):\n",
    "    models[i].load_state_dict(model_structure)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for _X, _Y in train_loader:\n",
    "    \n",
    "    X.append(_X.cpu().detach().numpy())\n",
    "    Y.append(_Y.cpu().detach().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(np.array(X[:-1]))\n",
    "Y = torch.tensor(np.array(Y[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.view(-1, 1, 28, 28)\n",
    "Y = Y.view(59968, 1)\n",
    "Y = Y.type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = []\n",
    "new_y = []\n",
    "\n",
    "for i in range(number_of_computers):\n",
    "    new_x.append(X[500 * i:500 * (i + 1)])\n",
    "    new_y.append(Y[500 * i:500 * (i + 1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this process took way too long so i just showing that the loss is reducing each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter  0  - loss  29.449348640441894\n",
      "Train iter  1  - loss  13.991734790802003\n",
      "Train iter  2  - loss  9.090677738189697\n",
      "Train iter  3  - loss  8.185234928131104\n",
      "Train iter  4  - loss  8.846930599212646\n",
      "Train iter  5  - loss  7.566807889938355\n",
      "Train iter  6  - loss  11.234913635253907\n",
      "Train iter  7  - loss  7.5950110912322994\n",
      "Train iter  8  - loss  11.735745525360107\n",
      "Train iter  9  - loss  7.641105699539184\n",
      "Train iter  10  - loss  6.588645935058594\n",
      "Train iter  11  - loss  6.095240068435669\n",
      "Train iter  12  - loss  6.293829679489136\n",
      "Train iter  13  - loss  7.651901054382324\n",
      "Train iter  14  - loss  6.987310409545898\n",
      "Train iter  15  - loss  6.397413158416748\n",
      "Train iter  16  - loss  6.95592474937439\n",
      "Train iter  17  - loss  5.498495054244995\n",
      "Train iter  18  - loss  5.934660911560059\n",
      "Train iter  19  - loss  5.0179352283477785\n",
      "Train iter  20  - loss  6.276976633071899\n",
      "Train iter  21  - loss  4.9207618713378904\n",
      "Train iter  22  - loss  5.493824911117554\n",
      "Train iter  23  - loss  5.244999170303345\n",
      "Train iter  24  - loss  4.90360312461853\n",
      "Train iter  25  - loss  4.857755470275879\n",
      "Train iter  26  - loss  5.469813394546509\n",
      "Train iter  27  - loss  4.835488367080688\n",
      "Train iter  28  - loss  5.253930902481079\n",
      "Train iter  29  - loss  4.34195613861084\n"
     ]
    }
   ],
   "source": [
    "w = 1000\n",
    "d = 25\n",
    "multi_party_training(models, new_x, new_y, number_of_computers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "30\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "it = np.arange(1,iteration+2)\n",
    "print(it)\n",
    "print(len(localLossLs))\n",
    "plt.plot(it,localLossLs,label = \"Local Training\")\n",
    "plt.plot(it,disLossLs,label = \"Distributed Training\")\n",
    "plt.title(\"Fully Connected Network : MSE Loss Over Iterations\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
